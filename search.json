[
  {
    "objectID": "awardees.html",
    "href": "awardees.html",
    "title": "JASA Reproducibility Awardees",
    "section": "",
    "text": "The JASA Editorial Board and Associate Editors for Reproducibility would like to congratulate the winners on their exceptional contributions to computational reproducibility within the statistical field! üèÖ\nThese awards are selected by the JASA Associate Editors of Reproducibility (AERs) and a description of the JASA Reproducibility Award is described here."
  },
  {
    "objectID": "awardees.html#section",
    "href": "awardees.html#section",
    "title": "JASA Reproducibility Awardees",
    "section": "2023",
    "text": "2023\n\nLucy L. Gao, Jacob Bien, Daniela Witten (2022). Selective Inference for Hierarchical Clustering, Journal of the American Statistical Association, DOI: 10.1080/01621459.2022.2116331\n\nR software package: http://lucylgao.com/clusterpval\nCode to reproduce results: https://github.com/lucylgao/clusterpval-experiments\n\nCecilia Balocchi, Sameer K. Deshpande, Edward I. George, Shane T. Jensen (2023). Crime in Philadelphia: Bayesian Clustering with Particle Optimization, Journal of the American Statistical Association, DOI: 10.1080/01621459.2022.2156348\n\nR software package: https://github.com/cecilia-balocchi/particle-optimization/tree/master/PARTOPT\nCode to reproduce results: https://github.com/cecilia-balocchi/particle-optimization"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "What is the JASA Reproducibility Initiative?",
    "section": "",
    "text": "In July 2016, the JASA Reproducibility Initiative was introduced, which aimed to increase the reproducibility of manuscripts published in JASA Applications and Case Studies (ACS). For example, in the first half of 2016, less than 20 percent of papers published in JASA ACS provided any supporting code or data that would enable reproduction of their results.\nIn 2021, the initiative celebrated its five-year anniversary and expanded the initiative to include JASA Theory and Methods manuscripts.\nAs of September 1, 2021, all original research manuscripts submitted to JASA undergoes a reproducibility review with authors required to provide their reproducibility materials when invited to revise their initial submission.\nCode for published papers are made available in GitHub repositories."
  },
  {
    "objectID": "about.html#the-team",
    "href": "about.html#the-team",
    "title": "What is the JASA Reproducibility Initiative?",
    "section": "The Team",
    "text": "The Team\nThe initiative is led by the lean, but mighty JASA Associate Editors for Reproducibility (AERs)."
  },
  {
    "objectID": "about.html#the-guide",
    "href": "about.html#the-guide",
    "title": "What is the JASA Reproducibility Initiative?",
    "section": "The Guide",
    "text": "The Guide\nThe JASA Reproducibility Guide provides guidance to both authors of manuscripts being submitted to JASA, but also guidance for the AERs who carry out the reproducibility review."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JASA Reproducibility Award",
    "section": "",
    "text": "Overview\nThe JASA Reproducibility Award, established in 2023 by the JASA Editorial board and implemented by the JASA Associate Editors of Reproducibility (AERs), aims to recognize outstanding papers from JASA Applications and Case Studies (ACS) or JASA Theory and Methods (TM) in terms of their computational reproducibility. This award will evaluate the code, data, and the workflow to reproduce the work presented in the paper as part of all invited revisions to Journal of the American Statistical Association (JASA).\nUp to three papers are selected every year by the AERs and an award is presented to the authors during the annual Joint Statistical Meetings (JSM) the following year at Computing and Graphics Joint Section Meeting.\nEach award comes with a $500 honorarium.\n\n\nGoals\nThis award aims to encourage computational reproducibility efforts in the statistical field and to reward outstanding papers that, by implementing rigorous reproducibility processes, increase access to important data, analytic tools, and workflows for the scientific community. Examples of outstanding reproducibility efforts include, but are not limited to:\n\nWriting reproducible code and analyses\nBuilding research objects (e.g.¬†workflows, software, benchmarks, computational environments, etc) to help others improve reproducibility of their own code and analyses\nGenerating open datasets/software of relevance to the scientific community\nEvaluating the reproducibility of results in the scientific literature\nDeveloping improved reproducibility processes and guidelines\n\n\n\nProcess and Criteria\n\nCriteria for eligibility of the award include\n\nAll papers that are accepted into JASA by December 31 are eligible for the award in the following year at JSM.\n\nProcess for selection of the award:\n\nEach AER can nominate at most three papers from the calendar year (e.g.¬†Jan 1 - Dec 31) to be discussed as potential candidates for the award.\nIn the spring before JSM, the AERs will eestablish criteria for comparing the nominated papers and each nominated paper will be rated by a randomly chosen subset of the AERs.\nThe AERs will determine the winners by consensus after discussion of top-rated papers.\n\nPost-selection award process:\n\nAERs will notify the winners by May before JSM.\nThe award would be presented at JSM in July or August.\nAuthors of each winning publication will be asked to decide how to split the honorarium.\nPapers from current AERs are not eligible to receive the award."
  }
]